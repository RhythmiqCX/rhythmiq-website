// app/api/voice-llm/route.ts
import { NextResponse } from "next/server";
import Groq from "groq-sdk";

const groq = new Groq({
  apiKey: process.env.GROQ_API_KEY!,
});

export async function POST(req: Request) {
  const { prompt } = await req.json();

  const completion = await groq.chat.completions.create({
    model: "llama-3.3-70b-versatile",
    messages: [
      { role: "system", content: "You are a helpful AI voice assistant." },
      { role: "user", content: prompt },
    ],
    stream: false,
  });

  return NextResponse.json({
    reply: completion.choices[0]?.message?.content,
  });
}
